{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ont Hot Encoding and Word Embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emos8lnE_pph",
        "outputId": "59ea4eea-626f-47b9-e4ec-2e7fc234c5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8713, 8284, 6517, 145], [8713, 8284, 6517, 6662], [5145, 693, 9083, 3593], [5145, 1519, 7845, 1621, 7845, 6548, 6900], [5145, 693, 9083, 4884]]\n",
            "[[   0    0    0    0 8713 8284 6517  145]\n",
            " [   0    0    0    0 8713 8284 6517 6662]\n",
            " [   0    0    0    0 5145  693 9083 3593]\n",
            " [   0 5145 1519 7845 1621 7845 6548 6900]\n",
            " [   0    0    0    0 5145  693 9083 4884]]\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.05477509e-02,  3.24947871e-02,  3.35136391e-02,\n",
              "        -1.25109330e-02,  3.65219973e-02, -1.48767121e-02,\n",
              "         4.76509444e-02, -1.66113749e-02, -6.16334379e-04,\n",
              "        -2.75611524e-02, -4.96529229e-02,  1.79517753e-02,\n",
              "         7.43584707e-03, -5.77070564e-03, -1.18853338e-02],\n",
              "       [-4.05477509e-02,  3.24947871e-02,  3.35136391e-02,\n",
              "        -1.25109330e-02,  3.65219973e-02, -1.48767121e-02,\n",
              "         4.76509444e-02, -1.66113749e-02, -6.16334379e-04,\n",
              "        -2.75611524e-02, -4.96529229e-02,  1.79517753e-02,\n",
              "         7.43584707e-03, -5.77070564e-03, -1.18853338e-02],\n",
              "       [-4.05477509e-02,  3.24947871e-02,  3.35136391e-02,\n",
              "        -1.25109330e-02,  3.65219973e-02, -1.48767121e-02,\n",
              "         4.76509444e-02, -1.66113749e-02, -6.16334379e-04,\n",
              "        -2.75611524e-02, -4.96529229e-02,  1.79517753e-02,\n",
              "         7.43584707e-03, -5.77070564e-03, -1.18853338e-02],\n",
              "       [-4.05477509e-02,  3.24947871e-02,  3.35136391e-02,\n",
              "        -1.25109330e-02,  3.65219973e-02, -1.48767121e-02,\n",
              "         4.76509444e-02, -1.66113749e-02, -6.16334379e-04,\n",
              "        -2.75611524e-02, -4.96529229e-02,  1.79517753e-02,\n",
              "         7.43584707e-03, -5.77070564e-03, -1.18853338e-02],\n",
              "       [ 1.26562975e-02,  3.29205506e-02, -3.33599076e-02,\n",
              "        -2.81043295e-02, -1.34138353e-02, -2.90464889e-02,\n",
              "         1.45722292e-02,  4.92456071e-02, -4.30617109e-02,\n",
              "         2.22864486e-02,  2.32365169e-02, -4.36783321e-02,\n",
              "         2.27559730e-03,  1.96474530e-02, -3.99624333e-02],\n",
              "       [-1.46507733e-02,  2.72010006e-02, -2.11649183e-02,\n",
              "         4.12717573e-02, -4.07320261e-03,  3.26380767e-02,\n",
              "         2.52059214e-02,  1.08192563e-02,  7.99328089e-03,\n",
              "         6.16794825e-03,  3.33450548e-02, -1.91238280e-02,\n",
              "         1.87168606e-02, -4.07207757e-04, -3.55137512e-03],\n",
              "       [ 4.08345573e-02,  4.64440249e-02,  4.67761047e-02,\n",
              "         3.26860882e-02,  1.98341720e-02,  2.09346674e-02,\n",
              "        -1.98099148e-02, -8.00348818e-04, -2.08818447e-02,\n",
              "         1.04905255e-02, -2.35968828e-03,  2.90797688e-02,\n",
              "         4.03466709e-02,  4.68719937e-02, -3.10927983e-02],\n",
              "       [ 2.45941915e-02, -1.40922442e-02, -3.23636532e-02,\n",
              "         3.14760543e-02,  3.55764665e-02,  3.71930934e-02,\n",
              "         8.59275460e-05,  4.81989272e-02,  3.14649381e-02,\n",
              "        -8.57841223e-04,  1.75565518e-02, -4.51166406e-02,\n",
              "        -3.60995159e-02,  1.13301054e-02,  1.60989426e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences # becuase every sentece must have the same number of words\n",
        "from keras.layers import Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "\n",
        "sentence=[\"the glass of milk\",\n",
        "          \"The glass of juice\",\n",
        "            \"im a good boy\",\n",
        "            \"im going to go to work soon\",\n",
        "            \"im a good guitarist\"]\n",
        "vocab_size=10000\n",
        "onehot_rep=[one_hot(word,vocab_size) for word in sentence] \n",
        "print(onehot_rep) # index of each word in one_hot \n",
        "\n",
        "\n",
        "#Embedding\n",
        "\n",
        "sent_lenght=8\n",
        "embbded_docs=pad_sequences(onehot_rep,padding=\"pre\",maxlen=sent_lenght) # added zero to the first #if padding=post add to last\n",
        "print(embbded_docs)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,15,input_length=sent_lenght))\n",
        "model.compile(\"adam\",\"mse\")\n",
        "\n",
        "\n",
        "model.predict(embbded_docs[0])\n",
        "\n"
      ]
    }
  ]
}